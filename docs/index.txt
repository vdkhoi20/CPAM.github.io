1:"$Sreact.fragment"
2:I[9766,[],""]
3:I[8924,[],""]
5:I[4431,[],"OutletBoundary"]
7:I[5278,[],"AsyncMetadataOutlet"]
9:I[4431,[],"ViewportBoundary"]
b:I[4431,[],"MetadataBoundary"]
c:"$Sreact.suspense"
e:I[7150,[],""]
:HL["/_next/static/css/8f2eae6b65e4de19.css","style"]
0:{"P":null,"b":"JGEsZ4xRdowrdP1a1a78c","p":"","c":["",""],"i":false,"f":[[["",{"children":["__PAGE__",{}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/8f2eae6b65e4de19.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":["$","body",null,{"className":"__variable_188709 __variable_9a8899 antialiased","children":["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L4",null,["$","$L5",null,{"children":["$L6",["$","$L7",null,{"promise":"$@8"}]]}]]}],{},null,false]},null,false],["$","$1","h",{"children":[null,[["$","$L9",null,{"children":"$La"}],null],["$","$Lb",null,{"children":["$","div",null,{"hidden":true,"children":["$","$c",null,{"fallback":null,"children":"$Ld"}]}]}]]}],false]],"m":"$undefined","G":["$e",[]],"s":false,"S":true}
a:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
6:null
f:I[622,[],"IconMark"]
8:{"metadata":[["$","title","0",{"children":"CPAM: Context-Preserving Adaptive Manipulation for Zero-Shot Real Image Editing"}],["$","meta","1",{"name":"description","content":"Context-Preserving Adaptive Manipulation (CPAM), a novel zero-shot framework for complicated, non-rigid real image editing."}],["$","link","2",{"rel":"shortcut icon","href":"/magic_wand.png"}],["$","link","3",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"16x16"}],["$","link","4",{"rel":"icon","href":"/magic_wand.png"}],["$","link","5",{"rel":"apple-touch-icon","href":"/magic_wand.png"}],["$","$Lf","6",{}]],"error":null,"digest":"$undefined"}
d:"$8:metadata"
4:["$","div",null,{"className":"min-h-screen bg-white text-gray-900","children":[["$","section",null,{"className":"py-12 px-4","children":["$","div",null,{"className":"max-w-6xl mx-auto text-center","children":[["$","h1",null,{"className":"text-4xl md:text-5xl lg:text-5xl font-normal leading-tight mb-8 px-4 flex flex-col items-center","children":[["$","span",null,{"className":"flex items-center gap-2","children":[["$","span",null,{"className":"bg-gradient-to-r from-black via-yellow-400 to-cyan-400 bg-clip-text text-transparent","children":"CPAM"}],["$","img",null,{"src":"/magic_wand.png","alt":"Eraser","className":"w-10 h-10 md:w-12 md:h-12 lg:w-14 lg:h-14 inline-block"}],["$","span",null,{"className":"text-cyan-600","children":": Context-Preserving Adaptive Manipulation"}]]}],["$","span",null,{"className":"text-cyan-600","children":"for Zero-Shot Real Image Editing"}]]}],["$","div",null,{"className":"text-lg md:text-xl mb-6 flex flex-wrap items-center justify-center gap-x-6 gap-y-2","children":[["$","span",null,{"children":[["$","a",null,{"href":"https://orcid.org/0000-0001-8831-8846","target":"_blank","rel":"noopener noreferrer","className":"text-sky-700 hover:text-sky-600 hover:underline","children":"Dinh-Khoi Vo"}],["$","sup",null,{"children":"1,2"}]]}],["$","span",null,{"children":[["$","a",null,{"href":"https://orcid.org/0000-0002-6249-0848","target":"_blank","rel":"noopener noreferrer","className":"text-sky-700 hover:text-sky-600 hover:underline","children":"Thanh-Toan Do"}],["$","sup",null,{"children":"3"}]]}],["$","span",null,{"children":[["$","a",null,{"href":"#","target":"_blank","rel":"noopener noreferrer","className":"text-sky-700 hover:text-sky-600 hover:underline","children":"Tam V. Nguyen"}],["$","sup",null,{"children":"4"}]]}],["$","span",null,{"children":[["$","a",null,{"href":"https://orcid.org/0000-0003-3046-3041","target":"_blank","rel":"noopener noreferrer","className":"text-sky-700 hover:text-sky-600 hover:underline","children":"Minh-Triet Tran"}],["$","sup",null,{"children":"1,2"}]]}],["$","span",null,{"children":[["$","a",null,{"href":"https://orcid.org/0000-0002-7363-2610","target":"_blank","rel":"noopener noreferrer","className":"text-sky-700 hover:text-sky-600 hover:underline","children":"Trung-Nghia Le"}],["$","sup",null,{"children":"1,2"}]]}]]}],["$","div",null,{"className":"text-base md:text-lg mb-4 flex flex-col items-center justify-center gap-y-2","children":[["$","span",null,{"children":[["$","sup",null,{"children":"1"}],"University of Science, VNU-HCM, Ho Chi Minh City, Vietnam"]}],["$","span",null,{"children":[["$","sup",null,{"children":"2"}],"Vietnam National University, Ho Chi Minh City, Vietnam"]}],["$","span",null,{"children":[["$","sup",null,{"children":"3"}],"Monash University, Melbourne, Victoria, Australia"]}],["$","span",null,{"children":[["$","sup",null,{"children":"4"}],"University of Dayton, Ohio, United States"]}]]}],["$","div",null,{"className":"text-base mb-8 italic","children":"vdkhoi@selab.hcmus.edu.vn, toan.do@monash.edu, tamnguyen@udayton.edu, {tmtriet, ltnghia}@fit.hcmus.edu.vn"}],["$","div",null,{"className":"flex flex-wrap items-center justify-center gap-8 mb-12","children":[["$","a",null,{"href":"https://arxiv.org/abs/2506.18438","className":"px-6 py-3 bg-slate-600 hover:bg-slate-500 rounded border border-slate-500 transition-colors","rel":"noopener noreferrer","children":"arXiv"}],["$","a",null,{"href":"#","className":"px-6 py-3 bg-slate-600 hover:bg-slate-500 rounded border border-slate-500 transition-colors cursor-not-allowed opacity-75 relative","title":"Coming soon","children":["Code",["$","span",null,{"className":"absolute -top-1 -right-1 bg-red-500 text-white text-xs px-1 py-0.5 rounded-full font-bold transform rotate-12","children":"Soon"}]]}],["$","a",null,{"href":"#","className":"px-6 py-3 bg-slate-600 hover:bg-slate-500 rounded border border-slate-500 transition-colors cursor-not-allowed opacity-75 relative","title":"Coming soon","children":["Gradio Demo",["$","span",null,{"className":"absolute -top-1 -right-1 bg-red-500 text-white text-xs px-1 py-0.5 rounded-full font-bold transform rotate-12","children":"Soon"}]]}]]}],"$L10"]}]}],"$L11","$L12","$L13","$L14","$L15","$L16","$L17","$L18"]}]
10:["$","div",null,{"className":"mb-12","children":["$","img",null,{"src":"/teaser.png","alt":"CPAM Teaser","className":"w-full max-w-4xl mx-auto rounded-lg shadow-lg"}]}]
19:T5db,Editing natural images using textual descriptions in text-to-image diffusion models remains a significant challenge, particularly in achieving consistent generation and handling complex, non-rigid objects. Existing methods often struggle to preserve textures and identity, require extensive fine-tuning, and exhibit limitations in editing specific spatial regions or objects while retaining background details. This paper proposes Context-Preserving Adaptive Manipulation (CPAM), a novel zero-shot framework for complicated, non-rigid real image editing. Specifically, we propose a preservation adaptation module that adjusts self-attention mechanisms to preserve and independently control the object and background effectively. This ensures that the objects' shapes, textures, and identities are maintained while keeping the background undistorted during the editing process using the mask guidance technique. Additionally, we develop a localized extraction module to mitigate the interference with the non-desired modified regions during conditioning in cross-attention mechanisms. We also introduce various mask-guidance strategies to facilitate diverse image manipulation tasks in a simple manner. Extensive experiments on our newly constructed Image Manipulation BenchmArk (IMBA), a robust benchmark dataset specifically designed for real image editing, demonstrate that our proposed method is the preferred choice among human raters, outperforming existing state-of-the-art editing techniques.11:["$","section",null,{"className":"py-12 px-4 bg-gray-100 text-gray-900","children":["$","div",null,{"className":"max-w-6xl mx-auto","children":["$","div",null,{"className":"flex gap-8","children":[["$","h2",null,{"className":"text-3xl font-bold uppercase min-w-fit","children":"Abstract"}],["$","p",null,{"className":"text-lg leading-relaxed","children":"$19"}]]}]}]}]
12:["$","section",null,{"className":"py-16 px-4 bg-gray-100 text-gray-900","children":["$","div",null,{"className":"max-w-6xl mx-auto","children":[["$","h2",null,{"className":"text-3xl font-bold uppercase text-center mb-6","children":"Approach"}],["$","div",null,{"children":[["$","p",null,{"className":"text-lg leading-relaxed mb-6","children":["We propose Context-Preserving Adaptive Manipulation (CPAM) to edit an image",["$","i",null,{"children":[" I",["$","sub",null,{"children":"s"}]]}]," using a source object mask ",["$","i",null,{"children":["M",["$","sub",null,{"children":"s"}]]}]," through the ",["$","code",null,{"children":"MaskInputModule"}],", which can derive the mask in various ways, such as manual drawing, click-based extraction, or text prompts using SAM and a target text prompt ",["$","i",null,{"children":["P",["$","sub",null,{"children":"t"}]]}]," to generate a new image",["$","i",null,{"children":[" I",["$","sub",null,{"children":"t"}]]}]," that aligns with ",["$","i",null,{"children":["P",["$","sub",null,{"children":"t"}]]}],". Notably,",["$","i",null,{"children":[" I",["$","sub",null,{"children":"t"}]]}]," may spatially differ from ",["$","i",null,{"children":["I",["$","sub",null,{"children":"s"}]]}],", modifying objects or background while keeping other regions unchanged. To achieve this, we introduce a preservation adaptation module that adjusts self-attention to align the semantic content from intermediate latent noise to the current edited noise, ensuring the retention of the original object and background during the editing process. To prevent unwanted changes from the target prompt in non-desired modified regions, we propose a localized extraction module that enables targeted editing while preserving the remaining details. Additionally, we propose mask-guidance strategies for diverse image manipulation tasks. Below are the overall CPAM architecture , and the zero-shot editing algorithm."]}],["$","div",null,{"className":"grid grid-cols-1 md:grid-cols-2 gap-6 mb-8","children":[["$","div",null,{"className":"bg-white rounded-lg p-6 border border-gray-200","children":[["$","h3",null,{"className":"text-lg font-semibold text-center mb-4 text-gray-800","children":"Overall Architecture"}],["$","img",null,{"src":"/Overall_Pipeline.png","alt":"Overall Pipeline Diagram","className":"w-full h-auto rounded"}]]}],["$","div",null,{"className":"bg-white rounded-lg p-6 border border-gray-200","children":[["$","h3",null,{"className":"text-lg font-semibold text-center mb-4 text-gray-800","children":"Detail Mechanism"}],["$","img",null,{"src":"/detail_mechanism.png","alt":"Detail Mechanism Diagram","className":"w-full h-auto rounded"}]]}]]}],["$","div",null,{"className":"bg-white rounded-lg p-6 border border-gray-200","children":[["$","h3",null,{"className":"text-lg font-semibold text-center mb-4 text-gray-800","children":"Zero-Shot Editing Algorithm"}],["$","img",null,{"src":"/algorithm.png","alt":"Zero-Shot Editing Algorithm","className":"w-full h-auto rounded"}]]}]]}]]}]}]
13:["$","section",null,{"className":"py-16 px-4 bg-white text-gray-900","children":["$","div",null,{"className":"max-w-7xl mx-auto","children":[["$","h2",null,{"className":"text-3xl font-bold uppercase text-center mb-6","children":"Qualitative Comparison"}],["$","p",null,{"className":"text-lg text-gray-700 leading-relaxed mb-8 max-w-4xl mx-auto","children":"Figure shows a qualitative comparison of CPAM against leading state-of-the-art image editing techniques. Our results demonstrate that CPAM consistently outperforms existing methods across various real image editing tasks, including object replacement, view/pose changes, object removal, background alteration, and addition of new objects. CPAM excels in its ability to modify diverse aspects of images while effectively preserving the original background and avoiding unintended modifications to non-target regions."}],["$","div",null,{"className":"bg-gray-50 rounded-lg p-6 border border-gray-200","children":["$","img",null,{"src":"/qualitative.png","alt":"Qualitative comparison of object removal methods","className":"w-full h-auto rounded shadow-lg"}]}]]}]}]
14:["$","section",null,{"className":"py-16 px-4 bg-gray-50 text-gray-900","children":["$","div",null,{"className":"max-w-7xl mx-auto","children":[["$","h2",null,{"className":"text-3xl font-bold uppercase text-center mb-6","children":"Quantitative Comparison"}],["$","p",null,{"className":"text-lg text-gray-700 leading-relaxed mb-12 max-w-5xl mx-auto text-center","children":"We conduct comprehensive quantitative evaluations and user studies to assess the effectiveness of CPAM against state-of-the-art image editing methods. We evaluate methods using multiple metrics including functional capabilities, text-image alignment (CLIPScore), background preservation (LPIPS), and subjective user ratings across key dimensions. Our evaluation dataset, IMBA (Image Manipulation BenchmArk), comprises 104 carefully curated samples with detailed annotations for diverse editing tasks including object retention, modification, and background alteration."}],["$","div",null,{"className":"bg-white rounded-lg p-6 border border-gray-200 mb-12","children":[["$","h3",null,{"className":"text-xl font-semibold text-center mb-4 text-gray-800","children":"Functional Capabilities Comparison"}],["$","p",null,{"className":"text-sm text-gray-600 text-center mb-4","children":["Functional comparison across editing methods. ‚úì indicates supported features, ‚úó indicates not supported. ",["$","span",null,{"className":"font-semibold","children":"Local Edit:"}]," region-specific editing. ",["$","span",null,{"className":"font-semibold","children":"Obj. Removal:"}]," object removal capability. ",["$","span",null,{"className":"font-semibold","children":"Caption-Free:"}]," no original image caption required. ",["$","span",null,{"className":"font-semibold","children":"Mask Ctrl:"}]," mask-based region control. ",["$","span",null,{"className":"font-semibold","children":"Hi-Guidance:"}]," compatibility with high classifier-free guidance scales."]}],["$","div",null,{"className":"overflow-x-auto","children":["$","table",null,{"className":"w-full border-collapse text-sm","children":[["$","thead",null,{"children":["$","tr",null,{"className":"bg-gray-100 border-b-2 border-gray-300","children":[["$","th",null,{"className":"border border-gray-300 px-4 py-2 text-left font-semibold","children":"Method"}],["$","th",null,{"className":"border border-gray-300 px-4 py-2 text-center font-semibold","children":"Local Edit"}],["$","th",null,{"className":"border border-gray-300 px-4 py-2 text-center font-semibold","children":"Obj. Removal"}],["$","th",null,{"className":"border border-gray-300 px-4 py-2 text-center font-semibold","children":"Caption-Free"}],["$","th",null,{"className":"border border-gray-300 px-4 py-2 text-center font-semibold","children":"Mask Ctrl"}],["$","th",null,{"className":"border border-gray-300 px-4 py-2 text-center font-semibold","children":"Hi-Guidance"}]]}]}],["$","tbody",null,{"children":[["$","tr",null,{"className":"border-b border-gray-200 hover:bg-gray-50","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"SDEdit"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úì"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}]]}],["$","tr",null,{"className":"border-b border-gray-200 hover:bg-gray-50","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"MasaCtrl"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úì"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úì"}],"$L1a","$L1b"]}],"$L1c","$L1d","$L1e","$L1f","$L20","$L21","$L22"]}]]}]}],"$L23"]}],"$L24","$L25"]}]}]
15:["$","section",null,{"className":"py-16 px-4 bg-gray-100 text-gray-900","children":["$","div",null,{"className":"max-w-4xl mx-auto","children":[["$","h2",null,{"className":"text-3xl font-bold uppercase text-center mb-6","children":"Demo Video"}],["$","div",null,{"className":"aspect-video bg-white rounded-lg overflow-hidden relative shadow-lg","children":["$","video",null,{"className":"w-full h-full object-cover","controls":true,"loop":true,"muted":true,"playsInline":true,"children":[["$","source",null,{"src":"/demo_video.mp4","type":"video/mp4"}],"Your browser does not support the video tag."]}]}]]}]}]
16:["$","section",null,{"className":"py-16 px-4 bg-white text-gray-900 border-t border-gray-200","children":["$","div",null,{"className":"max-w-6xl mx-auto","children":[["$","h2",null,{"className":"text-3xl font-bold uppercase text-center mb-6","children":"Application"}],["$","p",null,{"className":"text-lg text-gray-700 leading-relaxed mb-8 text-center max-w-4xl mx-auto","children":"CPAM is designed as a general, training-free attention manipulation framework that can be instantiated across diverse image editing scenarios. Below, we present representative systems that build directly on CPAM‚Äôs core mechanisms, demonstrating how its principles translate into interactive research prototypes and practical end-user applications as well as object removal and precise region-focused editing, illustrating its extensibility across problem settings."}],["$","div",null,{"className":"grid grid-cols-1 md:grid-cols-2 gap-6 mb-8","children":[["$","div",null,{"className":"bg-gray-50 rounded-lg p-6 border border-gray-200","children":[["$","h3",null,{"className":"text-2xl font-semibold text-gray-800 mb-3","children":"iCONTRA ‚Äî Interactive Concept Transfer (CHI '24)"}],["$","p",null,{"className":"text-lg text-gray-700 leading-relaxed mb-4","children":"iCONTRA further demonstrates CPAM‚Äôs applicability to concept-level consistency in creative workflows. It incorporates a CPAM-based zero-shot editing algorithm that progressively integrates visual information from initial exemplars without fine-tuning, enabling coherent concept transfer across generated items. This formulation allows designers to efficiently create high-quality, thematically consistent collections with reduced effort."}],["$","div",null,{"className":"flex flex-wrap items-center gap-3","children":[["$","a",null,{"href":"https://dl.acm.org/doi/full/10.1145/3613905.3650788","className":"inline-block bg-blue-600 text-white px-5 py-2 rounded-lg font-semibold hover:bg-blue-700 transition","target":"_blank","rel":"noopener noreferrer","children":"iCONTRA Paper ‚Üí"}],["$","div",null,{"className":"mt-4","children":["$","img",null,{"src":"/interface.png","alt":"iCONTRA Teaser","className":"w-full h-auto rounded shadow-lg"}]}]]}]]}],["$","div",null,{"className":"bg-gray-50 rounded-lg p-6 border border-gray-200","children":[["$","h3",null,{"className":"text-2xl font-semibold text-gray-800 mb-3","children":"EPEdit ‚Äî Efficient Photo Editor"}],["$","p",null,{"className":"text-lg text-gray-700 leading-relaxed mb-4","children":"EPEdit packages CPAM-based zero-shot editing algorithms into a practical end-user system for comprehensive photo manipulation. By leveraging CPAM‚Äôs training-free attention control, EPEdit supports a wide range of editing tasks‚Äîincluding object removal, replacement, pose adjustment, background modification, and thematic collection design‚Äîwhile maintaining efficiency, usability, and low deployment cost."}],["$","div",null,{"className":"flex items-center gap-3","children":["$","a",null,{"href":"https://link.springer.com/chapter/10.1007/978-981-96-4288-5_22","className":"inline-block bg-blue-600 text-white px-5 py-2 rounded-lg font-semibold hover:bg-blue-700 transition","target":"_blank","rel":"noopener noreferrer","children":"EPEdit Paper ‚Üí"}]}],["$","div",null,{"className":"mt-4","children":["$","img",null,{"src":"/teaser_epedit.png","alt":"EPEdit Teaser","className":"w-full h-auto rounded shadow-lg"}]}]]}]]}]]}]}]
17:["$","section",null,{"className":"py-16 px-4 bg-gray-50 text-gray-900 border-t border-gray-200","children":["$","div",null,{"className":"max-w-6xl mx-auto","children":[["$","div",null,{"className":"grid grid-cols-1 md:grid-cols-2 gap-6 mb-8","children":[["$","div",null,{"className":"bg-white rounded-lg p-6 border border-gray-300 shadow-md","children":[["$","h3",null,{"className":"text-2xl font-semibold text-gray-800 mb-3","children":"PANDORA ‚Äî Zero-Shot Object Removal"}],["$","p",null,{"className":"text-lg text-gray-700 leading-relaxed mb-4","children":"PANDORA represents the foundational instantiation of CPAM for prompt-free object removal. By operationalizing CPAM‚Äôs pixel-wise attention dissolution and localized attentional guidance, PANDORA enables precise, non-rigid, and scalable multi-object erasure in a single pass without fine-tuning or prompt engineering."}],["$","a",null,{"href":"https://pandora-laboratory.github.io/","className":"inline-block bg-blue-600 text-white px-5 py-2 rounded-lg font-semibold hover:bg-blue-700 transition","target":"_blank","rel":"noopener noreferrer","children":"Visit PANDORA ‚Üí"}],["$","div",null,{"className":"mt-4","children":["$","img",null,{"src":"/teaser_Pandora.png","alt":"PANDORA Project Teaser","className":"w-full h-auto rounded shadow-lg"}]}]]}],["$","div",null,{"className":"bg-white rounded-lg p-6 border border-gray-300 shadow-md","children":[["$","h3",null,{"className":"text-2xl font-semibold text-gray-800 mb-3","children":"FocusDiff ‚Äî Target-Aware Refocusing"}],["$","p",null,{"className":"text-lg text-gray-700 leading-relaxed mb-4","children":"Building upon the same CPAM principles, FocusDiff extends attention refocusing and preservation mechanisms to region-specific text-guided editing, addressing prompt brittleness, spillover artifacts, and failures on small or cluttered objects. CPAM‚Äôs localized preservation strategies naturally generalize to FocusDiff‚Äôs refocused cross-attention, further enabling globally consistent editing in challenging settings such as 360¬∞ indoor panoramas and virtual reality environments."}],["$","div",null,{"className":"flex items-center gap-3","children":["$","a",null,{"href":"#","className":"inline-block bg-blue-900 text-white px-5 py-2 rounded-lg font-semibold transition","children":"coming soon"}]}],["$","div",null,{"className":"mt-4","children":["$","img",null,{"src":"/teaser_focusdiff.png","alt":"FocusDiff Teaser","className":"w-full h-auto rounded shadow-lg"}]}]]}]]}],["$","div",null,{"className":"space-y-6","children":[["$","div",null,{"className":"bg-gray-50 border border-gray-200 rounded-lg p-6","children":[["$","h3",null,{"className":"text-lg font-semibold text-gray-800 mb-3","children":"CPAM (2025)"}],["$","pre",null,{"className":"bg-white border border-gray-300 rounded p-4 overflow-x-auto text-sm font-mono text-gray-700","children":"@article{vo2025cpam,\n  title={CPAM: Context-Preserving Adaptive Manipulation for Zero-Shot Real Image Editing},\n  author={Vo, Dinh-Khoi and Do, Thanh-Toan and Nguyen, Tam V and Tran, Minh-Triet and Le, Trung-Nghia},\n  journal={arXiv preprint arXiv:2506.18438},\n  year={2025}\n}"}]]}],["$","div",null,{"className":"bg-gray-50 border border-gray-200 rounded-lg p-6","children":[["$","h3",null,{"className":"text-lg font-semibold text-gray-800 mb-3","children":"EPEdit: Redefining Image Editing with Generative AI (2024)"}],["$","pre",null,{"className":"bg-white border border-gray-300 rounded p-4 overflow-x-auto text-sm font-mono text-gray-700","children":"@inproceedings{nguyen2024epedit,\n  title={EPEdit: Redefining Image Editing with Generative AI and User-Centric Design},\n  author={Nguyen, Hoang-Phuc and Vo, Dinh-Khoi and Do, Trong-Le and Nguyen, Hai-Dang and Nguyen, Tan-Cong and Nguyen, Vinh-Tiep and Nguyen, Tam V and Le, Khanh-Duy and Tran, Minh-Triet and Le, Trung-Nghia},\n  booktitle={International Symposium on Information and Communication Technology},\n  pages={272--283},\n  year={2024},\n  organization={Springer}\n}"}]]}],"$L26"]}]]}]}]
18:["$","section",null,{"className":"py-16 px-4 bg-gray-50 text-gray-900 border-t border-gray-200","children":["$","div",null,{"className":"max-w-6xl mx-auto","children":[["$","h2",null,{"className":"text-3xl font-bold uppercase text-center mb-6","children":"Acknowledgment"}],["$","div",null,{"className":"flex-1","children":[["$","div",null,{"className":"bg-amber-50 border border-amber-200 rounded-lg p-6 mb-6","children":[["$","div",null,{"className":"flex items-center gap-3 mb-4","children":[["$","span",null,{"className":"text-3xl","children":"üí∞"}],["$","h3",null,{"className":"text-xl font-semibold text-amber-900","children":"Funding and GPU Support"}]]}],["$","p",null,{"className":"text-lg leading-relaxed text-amber-800","children":"This research is funded by the Vietnam National Foundation for Science and Technology Development (NAFOSTED) under Grant Number 102.05-2023.31. This research used the GPUs provided by the Intelligent Systems Lab at the Faculty of Information Technology, University of Science, VNU-HCM."}]]}],["$","div",null,{"className":"bg-blue-50 border border-blue-200 rounded-lg p-6 mb-6","children":[["$","div",null,{"className":"flex items-center gap-3 mb-4","children":[["$","span",null,{"className":"text-3xl","children":"üôè"}],["$","h3",null,{"className":"text-xl font-semibold text-blue-900","children":"User Study Participants"}]]}],["$","p",null,{"className":"text-lg leading-relaxed text-blue-800","children":"We extend our heartfelt gratitude to all 20 participants who took part in our comprehensive user study. Your valuable time, thoughtful feedback, and detailed evaluations across 50 randomly shuffled images were instrumental in validating the effectiveness and usability of our CPAM framework. Your insights helped us understand the practical impact of our zero-shot real image editing approach and provided crucial evidence of its superiority over existing state-of-the-art methods."}]]}],["$","div",null,{"className":"bg-green-50 border border-green-200 rounded-lg p-6 mb-6","children":[["$","div",null,{"className":"flex items-center gap-3 mb-4","children":[["$","span",null,{"className":"text-3xl","children":"üé®"}],["$","h3",null,{"className":"text-xl font-semibold text-green-900","children":"Website Design Inspiration"}]]}],["$","p",null,{"className":"text-lg leading-relaxed text-green-800","children":["This website design is inspired by"," ",["$","a",null,{"href":"https://objectdrop.github.io/","className":"text-blue-600 hover:underline font-semibold","target":"_blank","rel":"noopener noreferrer","children":"ObjectDrop"}],". We thank the authors for their excellent work and creative design approach."]}]]}]]}]]}]}]
1a:["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úì"}]
1b:["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}]
1c:["$","tr",null,{"className":"border-b border-gray-200 hover:bg-gray-50","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"PnP"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}]]}]
1d:["$","tr",null,{"className":"border-b border-gray-200 hover:bg-gray-50","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"FPE"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}]]}]
1e:["$","tr",null,{"className":"border-b border-gray-200 hover:bg-gray-50","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"DiffEdit"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úì"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úì"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úì"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}]]}]
1f:["$","tr",null,{"className":"border-b border-gray-200 hover:bg-gray-50","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"Pix2Pix-Zero"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}]]}]
20:["$","tr",null,{"className":"border-b border-gray-200 hover:bg-gray-50","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"LEDITS++"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úì"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úì"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úì"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}]]}]
21:["$","tr",null,{"className":"border-b border-gray-200 hover:bg-gray-50","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"Imagic (FT)"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"‚úó"}]]}]
22:["$","tr",null,{"className":"bg-gray-100 border-b-2 border-gray-300 font-semibold","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"CPAM (Ours)"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center text-green-600","children":"‚úì"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center text-green-600","children":"‚úì"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center text-green-600","children":"‚úì"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center text-green-600","children":"‚úì"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center text-green-600","children":"‚úì"}]]}]
23:["$","p",null,{"className":"text-sm text-gray-700 mt-4 leading-relaxed","children":"CPAM is the only method that supports all five functional capabilities, demonstrating its versatility in handling diverse image editing tasks."}]
24:["$","div",null,{"className":"bg-white rounded-lg p-6 border border-gray-200 mb-12","children":[["$","h3",null,{"className":"text-xl font-semibold text-center mb-4 text-gray-800","children":"Comparison with State-of-the-Art Methods"}],["$","p",null,{"className":"text-sm text-gray-600 text-center mb-4","children":["Comparison using CLIPScore (measuring text-image alignment) and LPIPS background (evaluating background preservation). ",["$","span",null,{"className":"font-bold","children":"Bold"}]," indicates best scores, ",["$","span",null,{"className":"underline","children":"underline"}]," indicates second best."]}],["$","div",null,{"className":"overflow-x-auto","children":["$","table",null,{"className":"w-full border-collapse text-sm","children":[["$","thead",null,{"children":["$","tr",null,{"className":"bg-gray-100 border-b-2 border-gray-300","children":[["$","th",null,{"className":"border border-gray-300 px-4 py-2 text-left font-semibold","children":"Method"}],["$","th",null,{"className":"border border-gray-300 px-4 py-2 text-center font-semibold","children":"CLIPScore ‚Üë"}],["$","th",null,{"className":"border border-gray-300 px-4 py-2 text-center font-semibold","children":"LPIPS (bg) ‚Üì"}]]}]}],["$","tbody",null,{"children":[["$","tr",null,{"className":"border-b border-gray-200 hover:bg-gray-50","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"SDEdit"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"28.19"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"0.338"}]]}],["$","tr",null,{"className":"border-b border-gray-200 hover:bg-gray-50","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"MasaCtrl"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"28.82"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"0.223"}]]}],["$","tr",null,{"className":"border-b border-gray-200 hover:bg-gray-50","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"PnP"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"29.03"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"0.162"}]]}],["$","tr",null,{"className":"border-b border-gray-200 hover:bg-gray-50","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"FPE"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"29.02"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"0.152"}]]}],["$","tr",null,{"className":"border-b border-gray-200 hover:bg-gray-50","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"DiffEdit"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"28.58"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"0.148"}]]}],["$","tr",null,{"className":"border-b border-gray-200 hover:bg-gray-50","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"Pix2Pix-Zero"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"27.01"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"0.186"}]]}],["$","tr",null,{"className":"border-b border-gray-200 hover:bg-gray-50","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"LEDITS++"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"28.74"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":["$","span",null,{"className":"font-bold","children":"0.141"}]}]]}],["$","tr",null,{"className":"border-b border-gray-200 hover:bg-gray-50","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"Imagic (FT)"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":["$","span",null,{"className":"font-bold","children":"30.34"}]}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"0.420"}]]}],"$L27"]}]]}]}],"$L28"]}]
25:["$","div",null,{"className":"bg-white rounded-lg p-6 border border-gray-200","children":[["$","h3",null,{"className":"text-xl font-semibold text-center mb-4 text-gray-800","children":"User Study Results"}],["$","p",null,{"className":"text-sm text-gray-600 text-center mb-4","children":["Participants rated image editing methods on a scale of 1 (very bad) to 6 (very good). ",["$","span",null,{"className":"font-bold","children":"Bold"}]," indicates best scores, ",["$","span",null,{"className":"underline","children":"underline"}]," indicates second best."]}],["$","div",null,{"className":"overflow-x-auto","children":["$","table",null,{"className":"w-full border-collapse text-sm","children":[["$","thead",null,{"children":["$","tr",null,{"className":"bg-gray-100 border-b-2 border-gray-300","children":[["$","th",null,{"className":"border border-gray-300 px-4 py-2 text-left font-semibold","children":"Method"}],["$","th",null,{"className":"border border-gray-300 px-4 py-2 text-center font-semibold","children":"Object Retention"}],["$","th",null,{"className":"border border-gray-300 px-4 py-2 text-center font-semibold","children":"Background Retention"}],["$","th",null,{"className":"border border-gray-300 px-4 py-2 text-center font-semibold","children":"Realistic"}],["$","th",null,{"className":"border border-gray-300 px-4 py-2 text-center font-semibold","children":"Satisfaction"}]]}]}],["$","tbody",null,{"children":[["$","tr",null,{"className":"border-b border-gray-200 hover:bg-gray-50","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"SDEdit"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"3.63"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"3.19"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"3.38"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"2.42"}]]}],["$","tr",null,{"className":"border-b border-gray-200 hover:bg-gray-50","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"MasaCtrl"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"4.01"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"4.17"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"4.32"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"3.11"}]]}],["$","tr",null,{"className":"border-b border-gray-200 hover:bg-gray-50","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"PnP"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":["$","span",null,{"className":"underline","children":"4.61"}]}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"4.49"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"4.20"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"2.63"}]]}],["$","tr",null,{"className":"border-b border-gray-200 hover:bg-gray-50","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"FPE"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"4.50"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"4.44"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"4.33"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"2.53"}]]}],["$","tr",null,{"className":"border-b border-gray-200 hover:bg-gray-50","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"DiffEdit"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"4.58"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"4.57"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"4.40"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"3.13"}]]}],"$L29","$L2a","$L2b","$L2c"]}]]}]}],"$L2d"]}]
2e:T7b8,@inproceedings{10.1145/3613905.3650788,
author = {Vo, Dinh-Khoi and Ly, Duy-Nam and Le, Khanh-Duy and Nguyen, Tam V. and Tran, Minh-Triet and Le, Trung-Nghia},
title = {iCONTRA: Toward Thematic Collection Design Via Interactive Concept Transfer},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650788},
doi = {10.1145/3613905.3650788},
abstract = {Creating thematic collections in industries demands innovative designs and cohesive concepts. Designers may face challenges in maintaining thematic consistency when drawing inspiration from existing objects, landscapes, or artifacts. While AI-powered graphic design tools offer help, they often fail to generate cohesive sets based on specific thematic concepts. In response, we introduce iCONTRA, an interactive CONcept TRAnsfer system. With a user-friendly interface, iCONTRA enables both experienced designers and novices to effortlessly explore creative design concepts and efficiently generate thematic collections. We also propose a zero-shot image editing algorithm, eliminating the need for fine-tuning models, which gradually integrates information from initial objects, ensuring consistency in the generation process without influencing the background. A pilot study suggests iCONTRA&apos;s potential to reduce designers&apos; efforts. Experimental results demonstrate its effectiveness in producing consistent and high-quality object concept transfers. iCONTRA stands as a promising tool for innovation and creative exploration in thematic collection design. The source code will be available at: https://github.com/vdkhoi20/iCONTRA.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {382},
numpages = {8},
keywords = {Diffusion model, Thematic collection design, Zero-shot image editing},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}26:["$","div",null,{"className":"bg-gray-50 border border-gray-200 rounded-lg p-6","children":[["$","h3",null,{"className":"text-lg font-semibold text-gray-800 mb-3","children":"iCONTRA: Interactive Concept Transfer (CHI 2024)"}],["$","pre",null,{"className":"bg-white border border-gray-300 rounded p-4 overflow-x-auto text-sm font-mono text-gray-700","children":"$2e"}]]}]
27:["$","tr",null,{"className":"bg-gray-100 border-b-2 border-gray-300 font-semibold","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"CPAM (Ours)"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":["$","span",null,{"className":"underline","children":"29.26"}]}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":["$","span",null,{"className":"underline","children":"0.149"}]}]]}]
28:["$","p",null,{"className":"text-sm text-gray-700 mt-4 leading-relaxed","children":"CPAM achieves high CLIP score alongside low structure distortion and background preservation, demonstrating superior editing capability."}]
29:["$","tr",null,{"className":"border-b border-gray-200 hover:bg-gray-50","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"Pix2Pix-Zero"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"2.11"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"4.23"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"1.84"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"1.93"}]]}]
2a:["$","tr",null,{"className":"border-b border-gray-200 hover:bg-gray-50","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"LEDIT++"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"4.38"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":["$","span",null,{"className":"underline","children":"4.95"}]}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":["$","span",null,{"className":"underline","children":"4.57"}]}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"3.26"}]]}]
2b:["$","tr",null,{"className":"border-b border-gray-200 hover:bg-gray-50","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"Imagic (FT)"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"3.74"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"3.48"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":"4.30"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":["$","span",null,{"className":"font-bold","children":"4.82"}]}]]}]
2c:["$","tr",null,{"className":"bg-gray-100 border-b-2 border-gray-300 font-semibold","children":[["$","td",null,{"className":"border border-gray-300 px-4 py-2","children":"CPAM (Ours)"}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":["$","span",null,{"className":"font-bold","children":"4.72"}]}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":["$","span",null,{"className":"font-bold","children":"5.09"}]}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":["$","span",null,{"className":"font-bold","children":"4.69"}]}],["$","td",null,{"className":"border border-gray-300 px-4 py-2 text-center","children":["$","span",null,{"className":"underline","children":"3.30"}]}]]}]
2d:["$","p",null,{"className":"text-sm text-gray-700 mt-4 leading-relaxed","children":"CPAM significantly outperforms existing methods, achieving the best user satisfaction scores in object retention, background retention, and realism."}]
